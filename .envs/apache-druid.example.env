# Java tuning
DRUID_XMX=512m
DRUID_XMS=512m
DRUID_MAXNEWSIZE=250m
DRUID_NEWSIZE=250m
DRUID_MAXDIRECTMEMORYSIZE=6172m
DRUID_SINGLE_NODE_CONF=micro-quickstart

## Druid Configuration
druid_emitter_logging_logLevel=debug

druid_extensions_loadList=["druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "postgresql-metadata-storage", "druid-s3-extensions", "druid-basic-security"]

druid_zk_service_host=zookeeper

druid_metadata_storage_host=
druid_metadata_storage_type=postgresql
druid_metadata_storage_connector_connectURI=jdbc:postgresql://postgres:5432/demodb
druid_metadata_storage_connector_user=admin
druid_metadata_storage_connector_password=password

druid_coordinator_balancer_strategy=cachingCost

druid_indexer_runner_javaOptsArray=["-server", "-Xmx512m", "-Xms512m", "-XX:MaxDirectMemorySize=3g", "-Duser.timezone=UTC", "-Dfile.encoding=UTF-8", "-Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager", "-XX:+ExitOnOutOfMemoryError", "-XX:+HeapDumpOnOutOfMemoryError", "-XX:HeapDumpPath=/var/log/druid/task/"]
druid_indexer_fork_property_druid_processing_buffer_sizeBytes=512MiB

druid_worker_capacity=8
druid_indexer_fork_property_druid_processing_numMergeBuffers=2
druid_indexer_fork_property_druid_processing_buffer_sizeBytes=100MiB
druid_indexer_fork_property_druid_processing_numThreads=1

druid_storage_type=local
druid_storage_storageDirectory=/opt/shared/segments
druid_indexer_logs_type=file
druid_indexer_logs_directory=/opt/shared/indexing-logs

druid_processing_numThreads=2
druid_processing_numMergeBuffers=2

DRUID_LOG4J=<?xml version="1.0" encoding="UTF-8" ?><Configuration status="WARN"><Appenders><Console name="Console" target="SYSTEM_OUT"><PatternLayout pattern="%d{ISO8601} %p [%t] %c - %m%n"/></Console></Appenders><Loggers><Root level="info"><AppenderRef ref="Console"/></Root><Logger name="org.apache.druid.jetty.RequestLog" additivity="false" level="DEBUG"><AppenderRef ref="Console"/></Logger></Loggers></Configuration>

## Authentication
druid_auth_authenticatorChain=["MyBasicMetadataAuthenticator"]
druid_auth_authenticator_MyBasicMetadataAuthenticator_type=basic
druid_auth_authenticator_MyBasicMetadataAuthenticator_initialAdminPassword=password
druid_auth_authenticator_MyBasicMetadataAuthenticator_initialInternalClientPassword=password
druid_auth_authenticator_MyBasicMetadataAuthenticator_credentialsValidator_type=metadata
druid_auth_authenticator_MyBasicMetadataAuthenticator_skipOnFailure=false
druid_auth_authenticator_MyBasicMetadataAuthenticator_authorizerName=MyBasicMetadataAuthorizer

## Escalator
druid_escalator_type=basic
druid_escalator_internalClientUsername=druid_system
druid_escalator_internalClientPassword=password
druid_escalator_authorizerName=MyBasicMetadataAuthorizer

## Authorizer
druid_auth_authorizers=["MyBasicMetadataAuthorizer"]
druid_auth_authorizer_MyBasicMetadataAuthorizer_type=basic

## Deep storage configuration
## Choices:local, noop, s3, hdfs, c*. The type of deep storage to use.
druid_storage_type=local

## Deep storage configuration for S3
# druid_storage_type=s3
# druid_storage_bucket=<Write Bucket Name>
# druid_storage_baseKey=<Write bucket\'s base directory>
# druid_s3_accessKey=access-key
# druid_s3_secretKey=secret-key
# druid_s3_protocol=http
# druid_s3_enabePathStyleAccess=true
# druid_s3_endpoint_signingRegion=us-east-1
# druid_s3_endpoint_url=<Write S3 Url e.g. http://host:port>

## Log Storage Configuration
# druid_indexer_logs_type=s3
# druid_indexer_logs_s3Bucket=<Write Bucket Name>
# druid_indexer_logs_s3Prefix=<Write bucket\'s directory prefix>